---
title: "Case Study 3"
author: "Tamanna Srivastava"
date: "6/13/2020"
output: html_document
---
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(tidyverse)
library(dplyr)
library(nnet) # for multinom
library(plyr) # for count
library(knitr) # for kable
library(randomForest) # for random forest
library(caTools) # for random forest
library(partykit) # for ctree
```

```{r}
load("S2_imputed.RData")
```

```{r dataproc}
# drop 5,6,7 labels
S2_imputed <- subset(S2_imputed, label!=5 & label!=6 & label!=7)
#change label to a factor
S2_imputed$label <- as.factor(S2_imputed$label)

# set 0 as the baseline
S2_imputed <- S2_imputed %>% mutate(label=relevel(label,ref="0"))

#add in time column
S2_imputed$Time<- seq(from = 0, to =nrow(S2_imputed)/700, by = 1/700)[-4165001]
```

```{r trainingset}
#get 20% of the dataset
#tind<- seq(1, nrow(S2_imputed), 5)
#S2_train <- S2_imputed[tind,]
#S2_test <- S2_imputed[-tind,]

S2_train <- S2_imputed[sample(nrow(S2_imputed), 100), ]#for training set on local
S2_test <- S2_imputed[sample(nrow(S2_imputed), 50), ]#for test set on local
```

```{r missclassrate}
mcr=NULL

# function to compute missclassification rate
avclassifyrate=function(train, test, model){
  rating=l1=l2=l3=l4=l0=NULL
  for (i in 1:5){
    t_rain <- train
    t_est <- test
    m1<- model
    # column of predicted classes
    t_est$predictions <- predict(m1, t_est)
    # 0-1 loss (overall)
    loss <- ifelse(t_est$label != t_est$predictions, 1, 0)
    rating <- c(rating, sum(loss==1)/length(loss)) #overall misclassification rate
    #missclassified0
    sub0<- subset(t_est, label==0)
    loss0 <- ifelse(sub0$label != sub0$predictions, 1, 0)
    l0<- c(l0, sum(loss0==1)/length(loss0))
    #missclassified1
    sub1<- subset(t_est, label==1)
    loss0 <- ifelse(sub1$label != sub1$predictions, 1, 0)
    l1<- c(l1, sum(loss0==1)/length(loss0))
    #missclassified2
    sub2<- subset(t_est, label==2)
    loss0 <- ifelse(sub2$label != sub2$predictions, 1, 0)
    l2<- c(l2, sum(loss0==1)/length(loss0))
    #missclassified3
    sub3<- subset(t_est, label==3)
    loss0 <- ifelse(sub3$label != sub3$predictions, 1, 0)
    l3<- c(l3, sum(loss0==1)/length(loss0))
    #missclassified4
    sub4<- subset(t_est, label==4)
    loss0 <- ifelse(sub4$label != sub4$predictions, 1, 0)
    l4<- c(l4, sum(loss0==1)/length(loss0))
  }
  mcr=as.data.frame(rbind(l0,l1,l2,l3,l4,rating))
  mcr$Average=rowMeans(mcr)
  return(mcr)
}

#compute missclassification rate for the full model with wrist and chest
#Model 1
mod1= multinom(label ~ chest_ACC_X + chest_ACC_Y + chest_ACC_Z + chest_ECG + chest_EMG + chest_EDA + chest_Temp + chest_Resp + 
wrist_ACC_X + wrist_ACC_Y + wrist_ACC_Z + wrist_BVP + wrist_EDA + wrist_Temp, data = S2_train)

#Model 2
mod2= multinom(label ~ (chest_ACC_X + chest_ACC_Y + chest_ACC_Z + chest_ECG + chest_EMG + chest_EDA + chest_Temp + chest_Resp + 
wrist_ACC_X + wrist_ACC_Y + wrist_ACC_Z + wrist_BVP + wrist_EDA + wrist_Temp)^2, data = S2_train)

# Model 3
mod3= multinom(label ~ (chest_ACC_X + chest_ACC_Y + chest_ACC_Z + chest_ECG + chest_EMG + chest_EDA + chest_Temp + chest_Resp + wrist_ACC_X + wrist_ACC_Y + wrist_ACC_Z + wrist_BVP + wrist_EDA + wrist_Temp)^2+wrist_ACC_X:wrist_ACC_Y:wrist_ACC_Z + chest_ACC_X:chest_ACC_Y:chest_ACC_Z, data = S2_train)

#Model 4
mod4=multinom(label ~ chest_ACC_X + chest_ACC_Y + chest_ACC_Z + chest_ECG + chest_EMG + chest_EDA + chest_Temp + chest_Resp + 
wrist_ACC_X + wrist_ACC_Y + wrist_ACC_Z + wrist_BVP + wrist_EDA + wrist_Temp + wrist_ACC_X:wrist_ACC_Y:wrist_ACC_Z + chest_ACC_X:chest_ACC_Y:chest_ACC_Z + chest_Temp:chest_EDA + chest_ECG:chest_Resp + chest_EMG:chest_EDA + wrist_EDA:wrist_Temp + wrist_BVP:wrist_Temp+ wrist_BVP:wrist_EDA, data = S2_train)

#Model 5 
mod5=multinom(label ~ chest_ACC_X + chest_ACC_Y + chest_ACC_Z + chest_ECG + chest_EMG + chest_EDA + chest_Temp + chest_Resp + 
wrist_ACC_X + wrist_ACC_Y + wrist_ACC_Z + wrist_BVP + wrist_EDA + wrist_Temp + wrist_ACC_X:wrist_ACC_Y:wrist_ACC_Z + chest_ACC_X:chest_ACC_Y:chest_ACC_Z + chest_Temp:chest_EDA + chest_ECG:chest_Resp + wrist_EDA:wrist_Temp + wrist_BVP:wrist_Temp+ wrist_BVP:wrist_EDA, data = S2_train)

#Model 6
mod6= multinom(label ~ chest_ACC_X + chest_ACC_Y + chest_ACC_Z + chest_ECG + chest_EMG + chest_EDA + chest_Temp + chest_Resp + wrist_ACC_X + wrist_ACC_Y + wrist_ACC_Z + wrist_BVP + wrist_EDA + wrist_Temp+(chest_ACC_X^2)+(chest_ACC_Y^2)+(chest_ACC_Z^2)+(chest_ECG^2)+(chest_EMG^2)+(chest_EDA^2)+(chest_Temp^2)+(chest_Resp^2)+(wrist_ACC_X^2)+(wrist_ACC_Y^2)+(wrist_ACC_Z^2)+(wrist_BVP^2)+(wrist_EDA^2)+(wrist_Temp^2) , data = S2_train)

#Model 7
mod7= multinom(label ~ chest_ACC_X + chest_ACC_Y + chest_ACC_Z + chest_ECG + chest_EMG + chest_EDA + chest_Temp + chest_Resp + wrist_ACC_X + wrist_ACC_Y + wrist_ACC_Z + wrist_BVP + wrist_EDA + wrist_Temp+ Time , data = S2_train)

#Get the MC Rates for the models
mcdat1=avclassifyrate(S2_train, S2_test, mod1)
mcdat2=avclassifyrate(S2_train, S2_test, mod2)
mcdat3=avclassifyrate(S2_train, S2_test, mod3)
mcdat4=avclassifyrate(S2_train, S2_test, mod4)
mcdat5=avclassifyrate(S2_train, S2_test, mod5)
mcdat6=avclassifyrate(S2_train, S2_test, mod6)
mcdat7=avclassifyrate(S2_train, S2_test, mod7)

#Get the average MC rate for each model and save as a S2_imputed
lab=c("MC Rate for Label=0","MC Rate for Label=1", "MC Rate for Label=2","MC Rate for Label=3","MC Rate for Label=4", "Overall MC Rate", "AIC")
mcav=as.data.frame(cbind(rowMeans(mcdat1), rowMeans(mcdat2), rowMeans(mcdat3), rowMeans(mcdat4), rowMeans(mcdat5),rowMeans(mcdat6),rowMeans(mcdat7)))

#bind AIC values to S2_imputed
mcav=rbind(mcav, c(summary(mod1)$AIC,summary(mod2)$AIC,summary(mod3)$AIC,summary(mod4)$AIC,summary(mod5)$AIC,summary(mod6)$AIC,summary(mod7)$AIC))

rownames(mcav)=lab
colnames(mcav)=c("Average for M1", "Average for M2", "Average for M3", "Average for M4","Average for M5","Average for M6","Average for M7")
mcav
```
```{r compmod}
#compare models using drop in deviance
#no interaction and two way
as.data.frame(anova(mod1, mod2, test = "Chisq")) #check if 2 way interactions are significant
as.data.frame(anova(mod1, mod3, test = "Chisq")) #check if selected 3 way interactions are significant
as.data.frame(anova(mod1, mod4, test = "Chisq")) #check if selected interactions are significant
as.data.frame(anova(mod1, mod5, test = "Chisq")) #check if selected interactions are significant
as.data.frame(anova(mod1, mod6, test = "Chisq")) #check if quadratics are significant
as.data.frame(anova(mod1, mod7, test = "Chisq")) #check if time is significant

###none are significant 
```


```{r chosen}
subtrain=S2_train[,-17]
subtest=S2_test[,-17]

#mfin is the chosen model
mfin <- multinom(label ~ chest_ACC_X + chest_ACC_Y + chest_ACC_Z + chest_ECG + chest_EMG + chest_EDA + chest_Temp + chest_Resp + 
                 wrist_ACC_X + wrist_ACC_Y + wrist_ACC_Z + wrist_BVP + wrist_EDA + wrist_Temp, data = subtrain)

# column of predicted classes
subtest$predictions <- predict(m1, subtest)

#plot of actual vs. predicted
ggplot(data=subtest, aes(predictions, label))+geom_point()+ggtitle("Actual vs. Predicted for Label")+xlab("Predicted")+ylab("Actual")

#residuals calculations (NEW)
#calc predicted probs
pred_probs <- as.data.frame(predict(mfin, type = "probs"))
colnames(pred_probs)<- c("pp0", "pp1", "pp2", "pp3", "pp4")
#calc residuals
residuals <- as.data.frame(residuals(mfin)) %>%  #calculate residuals
  setNames(paste('resid.', names(.), sep = "")) #update column names

subtest=cbind(subtest, pred_probs, residuals)

#only look at residuals and pred probs for subsets of levels and continuous predictors (3:16)
sub0=subtest[, c(3:16, 18, 23)]
sub1=subtest[, c(3:16, 19, 24)]
sub2=subtest[, c(3:16, 20 , 25)]
sub3=subtest[, c(3:16, 21, 26)]
sub4=subtest[, c(3:16, 22, 27)]

subtest
sub0

#Plots of Residuals vs Predictors for Label=0
for (i in 1:15){
  print(ggplot(data=sub0, aes(sub0[,i], resid.0))+geom_point()+xlab(colnames(sub0)[i])+ylab("Residuals  (Label=0)")+ggtitle(paste("Residuals vs.",colnames(sub0)[i])))
}

#Plots of Residuals vs Predictors for Label=1
for (i in 1:15){
  print(ggplot(data=sub1, aes(sub1[,i], resid.1))+geom_point()+xlab(colnames(sub1)[i])+ylab("Residuals (Label=1)")+ggtitle(paste("Residuals vs.",colnames(sub0)[i])))
}

#Plots of Residuals vs Predictors for Label=2
for (i in 1:15){
  print(ggplot(data=sub2, aes(sub2[,i], resid.2))+geom_point()+xlab(colnames(sub2)[i])+ylab("Residuals  (Label=2)")+ggtitle(paste("Residuals vs.",colnames(sub0)[i])))
}

#Plots of Residuals vs Predictors for Label=3
for (i in 1:15){
  print(ggplot(data=sub3, aes(sub3[,i], resid.3))+geom_point()+xlab(colnames(sub3)[i])+ylab("Residuals  (Label=3)")+ggtitle(paste("Residuals vs.",colnames(sub0)[i])))
}

#Plots of Residuals vs Predictors for Label=4
for (i in 1:15){
  print(ggplot(data=sub4, aes(sub4[,i], resid.4))+geom_point()+xlab(colnames(sub4)[i])+ylab("Residuals (Label=4)")+ggtitle(paste("Residuals vs.",colnames(sub0)[i])))
}
```

```{r randforest}
#random forest
rftrain=S2_train
rf <- randomForest(as.factor(label) ~ chest_ACC_X + chest_ACC_Y + chest_ACC_Z + chest_ECG + chest_EMG + chest_EDA + chest_Temp + chest_Resp + wrist_ACC_X + wrist_ACC_Y + wrist_ACC_Z + wrist_BVP + wrist_EDA + wrist_Temp,data=rftrain, ntree=5000)

rftrain$rfpred=predict(rf, S2_test)
#plot actual vs. predicted
ggplot(data=rftrain, aes(rfpred, label))+geom_point()+xlab("Predicted")+ylab("Actual")+ggtitle("Actual vs. Predicted for Random Forest")

#conditional inteference tree
ctmod <- ctree(as.factor(label) ~ chest_ACC_X + chest_ACC_Y + chest_ACC_Z + chest_ECG + chest_EMG + chest_EDA + chest_Temp + chest_Resp + wrist_ACC_X + wrist_ACC_Y + wrist_ACC_Z + wrist_BVP + wrist_EDA + wrist_Temp,data=rftrain)

rftrain$ctpred=predict(ctmod, S2_test)
#plot actual vs. predicted
ggplot(data=rftrain, aes(ctpred, label))+geom_point()+xlab("Predicted")+ylab("Actual")+ggtitle("Actual vs. Predicted for Conditional Inference Tree")

#actual predictions
rftrain$finpred=predict(mfin, S2_test)

#Make misclassification table
avsens=as.data.frame(cbind(avclassifyrate(S2_train, S2_test, rf)$Average,avclassifyrate(S2_train, S2_test, ctmod)$Average,avclassifyrate(S2_train, S2_test, mfin)$Average))
avsens

colnames(avsens)=c("Final Model", "Random Forest", "Conditional Inference Tree")
lab=c("MC Rate for Label=0","MC Rate for Label=1", "MC Rate for Label=2","MC Rate for Label=3","MC Rate for Label=4", "Overall MC Rate")
rownames(avsens)=lab

#Make percentage classification table
pclass=merge(count(rftrain$finpred), count(rftrain$rfpred), by="x", all=T)
pclass=merge(pclass,count(rftrain$ctpred), by="x", all=T)
pclass=pclass[,-1]
pclass=(pclass/nrow(rftrain))*100
#Calculate differences in classification relative to final model
diffrf=ifelse(rftrain$finpred==rftrain$rfpred,0,1)
diffct=ifelse(rftrain$finpred==rftrain$ctpred,0,1)
pclass=rbind(pclass, c(0,sum(diffrf), sum(diffct)))
rownames(pclass)=c("% Classified as 0","% Classified as 1","% Classified as 2","% Classified as 3","% Classified as 4", "Absolute Diff in Classification")
colnames(pclass)=c("Final Model","Random Forest", "Conditional Inference Tree")
pclass[is.na(pclass)]=0
pclass
```

```{r submodsforwrist}
# Check submodels for just wrist predictors
mcr=NULL
mcdat=NULL

#Model 1
m1 <- multinom(label ~ (wrist_ACC_X + wrist_ACC_Y + wrist_ACC_Z + wrist_BVP + wrist_EDA + wrist_Temp), data = S2_train)

#Model 2
m2 <- multinom(label ~ (wrist_ACC_X + wrist_ACC_Y + wrist_ACC_Z + wrist_BVP + wrist_EDA + wrist_Temp)^2, data = S2_train)

#Model 3
m3 <- multinom(label ~ (wrist_ACC_X + wrist_ACC_Y + wrist_ACC_Z + wrist_BVP + wrist_EDA + wrist_Temp)^3, data = S2_train)

#Model 4
m4 <- multinom(label ~ wrist_ACC_X + wrist_ACC_Y + wrist_ACC_Z + wrist_BVP + wrist_EDA + wrist_Temp + wrist_ACC_X:wrist_ACC_Y:wrist_ACC_Z + wrist_EDA:wrist_Temp + wrist_BVP:wrist_Temp+ wrist_BVP:wrist_EDA, data = S2_train)

#Model 5
m5 <- multinom(label ~ (wrist_ACC_X + wrist_ACC_Y + wrist_ACC_Z + wrist_BVP + wrist_EDA + wrist_Temp+Time), data = S2_train)

#get the AIC for eachh model
modaic=c(summary(m1)$AIC,summary(m2)$AIC,summary(m3)$AIC,summary(m4)$AIC, summary(m5)$AIC)
  
# column of predicted classes
S2_test$predm1 <- predict(m1, S2_test)
#plot Actual vs. Predicted
ggplot(data=S2_test, aes( predm1, label))+geom_point()+xlab("Predicted")+ylab("Actual")+ggtitle("Actual vs. Predicted for Model 1")

# column of predicted classes
S2_test$predm2 <- predict(m2, S2_test)
#plot Actual vs. Predicted
ggplot(data=S2_test, aes(predm2, label))+geom_point()+xlab("Predicted")+ylab("Actual")+ggtitle("Actual vs. Predicted for Model 2")

# column of predicted classes
S2_test$predm3 <- predict(m3, S2_test)
#plot Actual vs. Predicted
ggplot(data=S2_test, aes(predm3, label))+geom_point()+xlab("Predicted")+ylab("Actual")+ggtitle("Actual vs. Predicted for Model 3")

# column of predicted classes
S2_test$predm4 <- predict(m4, S2_test)
#plot Actual vs. Predicted
ggplot(data=S2_test, aes(predm4, label))+geom_point()+xlab("Predicted")+ylab("Actual")+ggtitle("Actual vs. Predicted for Model 4")

# column of predicted classes
S2_test$predm5 <- predict(m5, S2_test)
#plot Actual vs. Predicted
ggplot(data=S2_test, aes(predm5, label))+geom_point()+xlab("Predicted")+ylab("Actual")+ggtitle("Actual vs. Predicted for Model 5")

#Get the MC Rates for the models
m1rate=avclassifyrate(S2_train, S2_test, m1)
m2rate=avclassifyrate(S2_train, S2_test, m2)
m3rate=avclassifyrate(S2_train, S2_test, m3)
m4rate=avclassifyrate(S2_train, S2_test, m4)
m5rate=avclassifyrate(S2_train, S2_test, m5)


#Get the average MC rate for each model and save as a S2_imputed
mcdat=as.data.frame(cbind(m1rate$Average, m2rate$Average, m3rate$Average,m4rate$Average, m5rate$Average))
mcdat=rbind(mcdat, modaic)
lab=c("MC Rate for Label=0","MC Rate for Label=1", "MC Rate for Label=2","MC Rate for Label=3","MC Rate for Label=4", "Overall MC Rate", "AIC")
rownames(mcdat)=lab
colnames(mcdat)=c("Model 1", "Model 2", "Model 3", "Model4", "Model 5")

mcdat
```

